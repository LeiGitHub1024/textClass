from __future__ import unicode_literals

import json
import jieba
from tqdm import tqdm
import math
import re
from pandas import Series,DataFrame
import pandas as pd
import numpy as np

classes =['çƒ¦æ¼', 'æ¸¸æˆ', 'å•†ä¸š', 'å¨±ä¹', 'ç”Ÿæ´»', 'æ•™è‚²', 'å¥åº·', 'ç”µè„‘', 'ä½“è‚²', 'æ±½è½¦']   
classesMap ={'çƒ¦æ¼':0, 'æ¸¸æˆ':1, 'å•†ä¸š':2, 'å¨±ä¹':3, 'ç”Ÿæ´»':4, 'æ•™è‚²':5, 'å¥åº·':6, 'ç”µè„‘':7, 'ä½“è‚²':8, 'æ±½è½¦':9 }        

def NBC(train,valid):
    wordSet = {} #æ‰€æœ‰å‡ºç°è¿‡è¯
    classWordMap = {} #{"ä½“è‚²,å…¨å’æ‰“":1024}
    wordTotal = 0 #è¯æ€»æ•°
    uniqueWordCount = 0 #ä¸é‡å¤è¯æ€»æ•°
    classCountMap = {} #æ¯ä¸ªç±»çš„æ€»è¯æ•°
    classRatioMap = {} #æ¯ä¸ªç±»çš„è¯æ•°/è¯æ€»æ•°
    print("3 2 1 Ready Go !\nTraining ğŸš—")
    for class1 in classes:
        classCountMap[class1] = 0
    with open(train, encoding='utf-8') as f:
        for line in tqdm(f.readlines()):
            js = json.loads(line)
            mainClass = js['mainCategory']
            word_list = js['content'].split(',')
            for word in word_list:
                wordTotal += 1
                # æ›´æ–°classWordMap
                key = mainClass +','+ word
                if(key in classWordMap.keys()):
                    classWordMap[key] = classWordMap[key]+1
                else:
                    classWordMap[key] = 1
                # æ›´æ–°wordSet
                if(word in wordSet.keys()):
                    wordSet[word] = wordSet[word]+1
                else:
                    wordSet[word] = 1
                # æ›´æ–°classCountMap
                classCountMap[mainClass] += 1
    for class1 in classes:
        classRatioMap[class1] = classCountMap[class1] / wordTotal
    for _ in wordSet:
        uniqueWordCount += 1
    
    print('Validating ğŸšš')
    x1 = np.zeros((10,10),dtype=int) #çŸ©é˜µç”¨æ¥è®°å½•æ­£ç¡®ç‡
    with open(valid,'r') as f:
        for line in tqdm(f.readlines()):
            posibility = {}
            js = json.loads(line)
            mainCategory = js['mainCategory']
            seg_list = js['content'].split(',')
            for class1 in classes:
                posib = math.log(classRatioMap[class1]) 
                for word in seg_list:
                    if word == '':
                        continue
                    key = class1 +','+ word
                    if key in classWordMap:  
                        posib += math.log((classWordMap[key]+1)/(classCountMap[class1]+uniqueWordCount))
                    else:
                        posib += math.log(1/(classCountMap[class1]+uniqueWordCount))
                posibility[class1] = posib
            trueCategory = mainCategory
            predictCategory = max(posibility, key=posibility.get)
            x1[classesMap[predictCategory]][classesMap[trueCategory]] += 1
    df = pd.DataFrame(columns=classes, index=classes, data=x1)
    df["è¡Œå’Œ"] =df.apply(lambda x:x.sum(),axis =1)
    df.loc["åˆ—å’Œ"] =df.apply(lambda x:x.sum()) 
    print(df)
    accuracy = {}
    recall = {}
    F1Score = {}
    for class1 in classes:
        accuracy[class1] = df[class1][class1] / df[class1]['åˆ—å’Œ']
        recall[class1] = df[class1][class1] / df['è¡Œå’Œ'][class1]
        F1Score[class1] = 2 * accuracy[class1] * recall[class1] / (accuracy[class1] + recall[class1])
    print("accuracy:",accuracy)
    print("recall:",recall)
    print("F1Score:",F1Score)
    print("accuracy_avg:",dict_Avg(accuracy))
    print("recall_avg:",dict_Avg(recall))
    print("F1Score_avg:",dict_Avg(F1Score))


def dict_Avg( Dict ) :
    L = len( Dict )						#å–å­—å…¸ä¸­é”®å€¼å¯¹çš„ä¸ªæ•°
    S = sum( Dict.values() )				#å–å­—å…¸ä¸­é”®å¯¹åº”å€¼çš„æ€»å’Œ
    A = S / L
    return A

NBC('./data/train_cut.json','./data/valid_cut.json')



